{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNmW3r1o7VMRJBiTeZ2cAm4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4bVdD4qOAvo",
        "colab_type": "text"
      },
      "source": [
        "# Classification of Alzheimer's Diseases using Quantification of HippoCampal Volume\n",
        "\n",
        "### Exploratory Data Analysis - Section 2 - Recursive UNet Model\n",
        "\n",
        "This task involves building recursive UNet model, training, logging and testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g08K4QTqjIuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "\n",
        "from torch import nn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbldBKXNjQLG",
        "colab_type": "text"
      },
      "source": [
        "Copyright 2017 Division of Medical Image Computing, German Cancer Research Center (DKFZ)\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "you may not use this file except in compliance with the License.\n",
        "You may obtain a copy of the License at\n",
        "\n",
        "     http://www.apache.org/licenses/LICENSE-2.0\n",
        "\n",
        " Unless required by applicable law or agreed to in writing, software\n",
        " distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        " WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        " See the License for the specific language governing permissions and\n",
        " limitations under the License.\n",
        "\n",
        " Defines the Unet.\n",
        " |num_downs|: number of downsamplings in UNet. For example,\n",
        " if |num_downs| == 7, image of size 128x128 will become of size 1x1 at the bottleneck\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aodxtbjcjNJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes=3, in_channels=1, initial_filter_size=64, kernel_size=3, num_downs=4, norm_layer=nn.InstanceNorm2d):\n",
        "        # norm_layer=nn.BatchNorm2d, use_dropout=False):\n",
        "        super(UNet, self).__init__()\n",
        "\n",
        "        # construct unet structure\n",
        "        unet_block = UnetSkipConnectionBlock(in_channels=initial_filter_size * 2 ** (num_downs-1), out_channels=initial_filter_size * 2 ** num_downs,\n",
        "                                             num_classes=num_classes, kernel_size=kernel_size, norm_layer=norm_layer, innermost=True)\n",
        "        for i in range(1, num_downs):\n",
        "            unet_block = UnetSkipConnectionBlock(in_channels=initial_filter_size * 2 ** (num_downs-(i+1)),\n",
        "                                                 out_channels=initial_filter_size * 2 ** (num_downs-i),\n",
        "                                                 num_classes=num_classes, kernel_size=kernel_size, submodule=unet_block, norm_layer=norm_layer)\n",
        "        unet_block = UnetSkipConnectionBlock(in_channels=in_channels, out_channels=initial_filter_size,\n",
        "                                             num_classes=num_classes, kernel_size=kernel_size, submodule=unet_block, norm_layer=norm_layer,\n",
        "                                             outermost=True)\n",
        "\n",
        "        self.model = unet_block\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "\n",
        "# Defines the submodule with skip connection.\n",
        "# X -------------------identity---------------------- X\n",
        "#   |-- downsampling -- |submodule| -- upsampling --|\n",
        "class UnetSkipConnectionBlock(nn.Module):\n",
        "    def __init__(self, in_channels=None, out_channels=None, num_classes=1, kernel_size=3,\n",
        "                 submodule=None, outermost=False, innermost=False, norm_layer=nn.InstanceNorm2d, use_dropout=False):\n",
        "        super(UnetSkipConnectionBlock, self).__init__()\n",
        "        self.outermost = outermost\n",
        "        # downconv\n",
        "        pool = nn.MaxPool2d(2, stride=2)\n",
        "        conv1 = self.contract(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, norm_layer=norm_layer)\n",
        "        conv2 = self.contract(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size, norm_layer=norm_layer)\n",
        "\n",
        "        # upconv\n",
        "        conv3 = self.expand(in_channels=out_channels*2, out_channels=out_channels, kernel_size=kernel_size)\n",
        "        conv4 = self.expand(in_channels=out_channels, out_channels=out_channels, kernel_size=kernel_size)\n",
        "\n",
        "        if outermost:\n",
        "            final = nn.Conv2d(out_channels, num_classes, kernel_size=1)\n",
        "            down = [conv1, conv2]\n",
        "            up = [conv3, conv4, final]\n",
        "            model = down + [submodule] + up\n",
        "        elif innermost:\n",
        "            upconv = nn.ConvTranspose2d(in_channels*2, in_channels,\n",
        "                                        kernel_size=2, stride=2)\n",
        "            model = [pool, conv1, conv2, upconv]\n",
        "        else:\n",
        "            upconv = nn.ConvTranspose2d(in_channels*2, in_channels, kernel_size=2, stride=2)\n",
        "\n",
        "            down = [pool, conv1, conv2]\n",
        "            up = [conv3, conv4, upconv]\n",
        "\n",
        "            if use_dropout:\n",
        "                model = down + [submodule] + up + [nn.Dropout(0.5)]\n",
        "            else:\n",
        "                model = down + [submodule] + up\n",
        "\n",
        "        self.model = nn.Sequential(*model)\n",
        "\n",
        "    @staticmethod\n",
        "    def contract(in_channels, out_channels, kernel_size=3, norm_layer=nn.InstanceNorm2d):\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=1),\n",
        "            norm_layer(out_channels),\n",
        "            nn.LeakyReLU(inplace=True))\n",
        "        return layer\n",
        "\n",
        "    @staticmethod\n",
        "    def expand(in_channels, out_channels, kernel_size=3):\n",
        "        layer = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size, padding=1),\n",
        "            nn.LeakyReLU(inplace=True),\n",
        "        )\n",
        "        return layer\n",
        "\n",
        "    @staticmethod\n",
        "    def center_crop(layer, target_width, target_height):\n",
        "        batch_size, n_channels, layer_width, layer_height = layer.size()\n",
        "        xy1 = (layer_width - target_width) // 2\n",
        "        xy2 = (layer_height - target_height) // 2\n",
        "        return layer[:, :, xy1:(xy1 + target_width), xy2:(xy2 + target_height)]\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.outermost:\n",
        "            return self.model(x)\n",
        "        else:\n",
        "            crop = self.center_crop(self.model(x), x.size()[2], x.size()[3])\n",
        "            return torch.cat([x, crop], 1)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
