{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP+8DTSId8cdkuwh3U/z8jT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4bVdD4qOAvo",
        "colab_type": "text"
      },
      "source": [
        "# Classification of Alzheimer's Diseases using Quantification of HippoCampal Volume\n",
        "\n",
        "### Exploratory Data Analysis - Section 2 - SlicesDataset\n",
        "\n",
        "This task involves building recursive UNet model, training, logging and testing. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g08K4QTqjIuR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "#from torch.utils.data import Dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AbldBKXNjQLG",
        "colab_type": "text"
      },
      "source": [
        "This module supports Pytorch's dataset representations by slicing the 3D image and label tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aodxtbjcjNJm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SlicesDataset(Dataset):\n",
        "    \"\"\"\n",
        "    This class represents an indexable Torch dataset\n",
        "    which could be consumed by the PyTorch DataLoader class\n",
        "    \"\"\"\n",
        "    def __init__(self, data):\n",
        "        self.data = data\n",
        "\n",
        "        self.slices = []\n",
        "\n",
        "        for i, d in enumerate(data):\n",
        "            for j in range(d[\"image\"].shape[0]):\n",
        "                self.slices.append((i, j))\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \"\"\"\n",
        "        This method is called by PyTorch DataLoader class to return a sample with id idx\n",
        "\n",
        "        Arguments: \n",
        "            idx {int} -- id of sample\n",
        "\n",
        "        Returns:\n",
        "            Dictionary of 2 Torch Tensors of dimensions [1, 1, W, H]\n",
        "        \"\"\"\n",
        "        slc = self.slices[idx]\n",
        "        sample = dict()\n",
        "        sample[\"id\"] = idx\n",
        "\n",
        "        # You could implement caching strategy here if dataset is too large to fit\n",
        "        # in memory entirely\n",
        "        # Also this would be the place to call transforms if data augmentation is used\n",
        "        \"\"\"\n",
        "        Data augmentation strategies has been elaborated in Section2/Standout.pdf. \n",
        "        Please check for research and implementations.\n",
        "        \"\"\"\n",
        "        \n",
        "        # Create two new keys in the \"sample\" dictionary, named \"image\" and \"seg\"\n",
        "        # The values are 3D Torch Tensors with image and slice data respectively. \n",
        "        # First dimension is size 1, and last two hold the voxel data from the respective\n",
        "        # slices. Write code that stores the 2D slice data in the last 2 dimensions of the 3D Tensors. \n",
        "        # Your tensor needs to be of shape [1, patch_size, patch_size]\n",
        "        # Don't forget that you need to put a Torch Tensor into your dictionary element's value\n",
        "        # Hint: your 3D data sits in self.data variable, the id of the 3D volume from data array\n",
        "        # and the slice number are in the slc variable. \n",
        "        # Hint2: You can use None notation like so: arr[None, :] to add size-1 \n",
        "        # dimension to a Numpy array\n",
        "\n",
        "        x = self.data[slc[0]][\"image\"][slc[1]]\n",
        "        sample[\"image\"] = torch.from_numpy(x).type(torch.FloatTensor) #use cuda if available\n",
        "        sample[\"image\"] = sample[\"image\"].unsqueeze(0) \n",
        "        x = self.data[slc[0]][\"seg\"][slc[1]]\n",
        "        sample[\"seg\"] = torch.from_numpy(x).type(torch.FloatTensor) #use cuda if available\n",
        "        sample[\"seg\"] = sample[\"seg\"].unsqueeze(0) \n",
        "        #print(sample[\"image\"].shape)\n",
        "        #print(sample[\"seg\"].shape)\n",
        "        return sample\n",
        "        \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"\n",
        "        This method is called by PyTorch DataLoader class to return number of samples in the dataset\n",
        "\n",
        "        Returns:\n",
        "            int\n",
        "        \"\"\"\n",
        "        return len(self.slices)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dwW7Ru0jzsf",
        "colab_type": "text"
      },
      "source": [
        "## Suggestion: \n",
        "\n",
        "Please provide a sample representation of self.data here. It is not completely obvious as to what the structure of this data is. \n",
        "\n",
        "Structure of self.data:\n",
        "\n",
        "\n",
        "```\n",
        " {'image': array([[[0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        ...,\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.]],\n",
        "\n",
        "       [[0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        ...,\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.]],\n",
        "\n",
        "       [[0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        ...,\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.]],\n",
        "\n",
        "       ...,\n",
        "\n",
        "       [[0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        ...,\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.]],\n",
        "\n",
        "       [[0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        ...,\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.]],\n",
        "\n",
        "       [[0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        ...,\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.],\n",
        "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32), 'seg': array([[[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        ...,\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0]],\n",
        "\n",
        "       [[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        ...,\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0]],\n",
        "\n",
        "       [[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        ...,\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0]],\n",
        "\n",
        "       ...,\n",
        "\n",
        "       [[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        ...,\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0]],\n",
        "\n",
        "       [[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        ...,\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0]],\n",
        "\n",
        "       [[0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        ...,\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0],\n",
        "        [0, 0, 0, ..., 0, 0, 0]]]), 'filename': 'hippocampus_048.nii.gz'}\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1tCv7Un4k8nR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
