{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset for hippocampus segmentation\n",
    "\n",
    "In this notebook you will use the skills and methods that we have talked about during our EDA Lesson to prepare the hippocampus dataset using Python. Follow the Notebook, writing snippets of code where directed so using Task comments, similar to the one below, which expects you to put the proper imports in place. Write your code directly in the cell with TASK comment. Feel free to add cells as you see fit, but please make sure that code that performs that tasked activity sits in the same cell as the Task comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Import the following libraries that we will use: nibabel, matplotlib, numpy\n",
    "import nibabel as nib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will help your understanding of the data a lot if you were able to use a tool that allows you to view NIFTI volumes, like [3D Slicer](https://www.slicer.org/). I will refer to Slicer throughout this Notebook and will be pasting some images showing what your output might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NIFTI images using NiBabel\n",
    "\n",
    "NiBabel is a python library for working with neuro-imaging formats (including NIFTI) that we have used in some of the exercises throughout the course. Our volumes and labels are in NIFTI format, so we will use nibabel to load and inspect them.\n",
    "\n",
    "NiBabel documentation could be found here: https://nipy.org/nibabel/\n",
    "\n",
    "Our dataset sits in two directories - *images* and *labels*. Each image is represented by a single file (we are fortunate to have our data converted to NIFTI) and has a corresponding label file which is named the same as the image file.\n",
    "\n",
    "Note that our dataset is \"dirty\". There are a few images and labels that are not quite right. They should be quite obvious to notice, though. The dataset contains an equal amount of \"correct\" volumes and corresponding labels, and you don't need to alter values of any samples in order to get the clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 51, 35)\n",
      "(35, 51, 35)\n"
     ]
    }
   ],
   "source": [
    "# TASK: Your data sits in directory /data/TrainingSet.\n",
    "# Load an image and a segmentation mask into variables called image and label\n",
    "image = nib.load(\"/Users/taruntalreja/Desktop/data/TrainingSet/images/hippocampus_001.nii.gz\")\n",
    "print(image.shape)\n",
    "label = nib.load(\"/Users/taruntalreja/Desktop/data/TrainingSet/labels/hippocampus_001.nii.gz\")\n",
    "print(label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nibabel can present your image data as a Numpy array by calling the method get_fdata()\n",
    "# The array will contain a multi-dimensional Numpy array with numerical values representing voxel intensities. \n",
    "# In our case, images and labels are 3-dimensional, so get_fdata will return a 3-dimensional array. You can verify this\n",
    "# by accessing the .shape attribute. What are the dimensions of the input arrays?\n",
    "\n",
    "# TASK: using matplotlib, visualize a few slices from the dataset, along with their labels. \n",
    "# You can adjust plot sizes like so if you find them too small:\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "def show_slices(slices):\n",
    "\t\"\"\" Function to display row of image slices \"\"\"\n",
    "\tfig, axes = plt.subplots(1, len(slices))\n",
    "\tfor i, slice in enumerate(slices):\n",
    "\t\taxes[i].imshow(slice.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "slice_a = label.get_fdata()[26, :, :]\n",
    "slice_b =  label.get_fdata()[:, 30, :]\n",
    "slice_c =  label.get_fdata()[:, :, 16]\n",
    "show_slices([slice_a, slice_b, slice_c])\n",
    "plt.suptitle(\"Label Slices\")  \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "slice_a = image.get_fdata()[26, :, :]\n",
    "slice_b =  image.get_fdata()[:, 30, :]\n",
    "slice_c =  image.get_fdata()[:, :, 16]\n",
    "show_slices([slice_a, slice_b, slice_c])\n",
    "plt.suptitle(\"Image Slices\")  \n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load volume into 3D Slicer to validate that your visualization is correct and get a feel for the shape of structures.Try to get a visualization like the one below (hint: while Slicer documentation is not particularly great, there are plenty of YouTube videos available! Just look it up on YouTube if you are not sure how to do something)\n",
    "\n",
    "![3D slicer](img/Slicer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img=mpimg.imread('/Users/taruntalreja/Desktop/Alzheimer-progression/img/Slicer.png')\n",
    "imgplot = plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at single image data\n",
    "In this section we will look closer at the NIFTI representation of our volumes. In order to measure the physical volume of hippocampi, we need to understand the relationship between the sizes of our voxels and the physical world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : \n",
      "db_name         : \n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : r\n",
      "dim_info        : 0\n",
      "dim             : [ 3 35 51 35  1  1  1  1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : uint8\n",
      "bitpix          : 8\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : 5.0.10\n",
      "aux_file        : none\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 1.0\n",
      "qoffset_y       : 1.0\n",
      "qoffset_z       : 1.0\n",
      "srow_x          : [1. 0. 0. 1.]\n",
      "srow_y          : [0. 1. 0. 1.]\n",
      "srow_z          : [0. 0. 1. 1.]\n",
      "intent_name     : \n",
      "magic           : n+1\n"
     ]
    }
   ],
   "source": [
    "# Nibabel supports many imaging formats, NIFTI being just one of them. I told you that our images \n",
    "# are in NIFTI, but you should confirm if this is indeed the format that we are dealing with\n",
    "# TASK: using .header_class attribute - what is the format of our images?\n",
    "# Slicer Render slicer image is based on below youtube video: \n",
    "# https://www.youtube.com/watch?v=MKLWzD0PiIc\n",
    "# img = mpimg.imread('slicer_render.png')\n",
    "# imgplot = plt.imshow(img)\n",
    "# plt.show()\n",
    "print(image.header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further down we will be inspecting .header attribute that provides access to NIFTI metadata. You can use this resource as a reference for various fields: https://brainder.org/2012/09/23/the-nifti-file-format/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: How many bits per pixel are used?\n",
    "# 8\n",
    "\n",
    "# TASK: What are the units of measurement?\n",
    "# xyzt_units\n",
    "\n",
    "# TASK: Do we have a regular grid? What are grid spacings?\n",
    "# The grid spacings is as follows:   \n",
    "# [1. 1. 1. 1. 1. 0. 0. 0.]\n",
    "\n",
    "# TASK: What dimensions represent axial, sagittal, and coronal slices? How do you know?\n",
    "# Affine attribute gives us information about the affine\n",
    "# Affine: array-like or None, optional. Affine transform for the data. \n",
    "# This is used to determine how the data should be sliced for plotting into the \n",
    "# sagittal, coronal, and axial view axes. If None, identity is assumed. \n",
    "# The aspect ratio of the data are inferred from the affine transform.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=3, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4151 3536 2873 2382 3654 3222 3442 3095 3686 3455 2956 2618 2930 2753\n",
      " 2451 3377 3724 3575 3113 3327 2863 2857 3994 3361 3208 3172 3445 3248\n",
      " 3568 3814 3229 2920 2819 3000 3356 3869 3660 3946 3372 3918 3845 3847\n",
      " 2697 3409 3423 3088 3831 3160 2714 3027 3478 3219 3000 3947 2943 3439\n",
      " 3304 3516 3109 3997 3707 3165 2570 2535 2755 3823 2684 3785 3450 3661\n",
      " 2588 3450 2870 3594 2948 3420 3435 3195 2613 3257 3127 3412 3479 3326\n",
      " 2726 3292 3522 2546 3061 3983 3325 2980 3987 3623 2590 3349 2678 3371\n",
      " 3216 2863 3856 3105 4071 2995 3773 3689 3335 3957 3671 3692 2593 3089\n",
      " 2920 2634 3820 3742 2708 3582 3506 3534 3404 3146 3409 3353 3923 3456\n",
      " 3220 2471 3658 3167 3252 3749 3600 3733 2945 3272 2629 3450 2416 2859\n",
      " 3704 3622 2593 3718 4263 3092 3650 3023 3700 3285 3080 3519 3202 3628\n",
      " 2714 3763 2950 2448 3340 4383 3374 3878 3150 3167 3605 2635 3431 2942\n",
      " 2757 2704 3029 3979 3285 3102 3877 2665 3612 3575 3679 2890 2647 3194\n",
      " 3210 2894 3502 4029 3581 3643 4401 3054 3333 3842 2830 2422 4074 2811\n",
      " 3698 3817 2739 3048 3940 3248 2397 2947 2738 2786 3611 3109 3251 3397\n",
      " 3097 2931 2827 3294 3483 3201 3208 3643 3309 3536 4001 3496 3040 2532\n",
      " 3438 3555 3509 2813 3152 3682 3137 4030 3674 3503 3145 3628 2534 3558\n",
      " 3536 2868 3375 3420 3728 3143 2773 3352 3955 3717 3456 3557 3398 3460\n",
      " 2678 3253 3177 3675 2912 3834 2475]\n"
     ]
    }
   ],
   "source": [
    "# By now you should have enough information to decide what are dimensions of a single voxel\n",
    "# TASK: Compute the volume (in mmÂ³) of a hippocampus using one of the labels you've loaded. \n",
    "# You should get a number between ~2200 and ~4500\n",
    "all_volumes=list()\n",
    "anterior_volumes=list()\n",
    "posterior_volumes=list()\n",
    "\n",
    "volume = 0\n",
    "\n",
    "sliced_labels = [[f,nib.load(os.path.join(\"/Users/taruntalreja/Desktop/data/TrainingSet/labels/\", f))] \n",
    "                for f in os.listdir(\"/Users/taruntalreja/Desktop/data/TrainingSet/labels/\")]\n",
    "\n",
    "def getVolume(label):\n",
    "    vol = 0\n",
    "    for i in range(label.shape[0]):\n",
    "        for j in range(label.shape[1]):\n",
    "            for k in range(label.shape[2]):\n",
    "                if label[i][j][k] != 0:\n",
    "                    vol += 1\n",
    "    return vol\n",
    "\n",
    "def getAnteriorVolume(label):\n",
    "    vol = 0\n",
    "    for i in range(label.shape[0]):\n",
    "        for j in range(label.shape[1]):\n",
    "            for k in range(label.shape[2]):\n",
    "                if label[i][j][k] == 1:\n",
    "                    vol += 1\n",
    "    return vol\n",
    "\n",
    "def getPosteriorVolume(label):\n",
    "    vol = 0\n",
    "    for i in range(label.shape[0]):\n",
    "        for j in range(label.shape[1]):\n",
    "            for k in range(label.shape[2]):\n",
    "                if label[i][j][k] == 2:\n",
    "                    vol += 1\n",
    "    return vol\n",
    "\n",
    "for idx in range(260):\n",
    "    t_label = sliced_labels[idx][1].get_fdata()\n",
    "    vol = getVolume(t_label)\n",
    "    all_volumes.append(vol)\n",
    "    anterior_volumes.append(getAnteriorVolume(t_label))\n",
    "    posterior_volumes.append(getPosteriorVolume(t_label))\n",
    "\n",
    "nonoutlier_volumes = np.array([v for v in all_volumes if (v<4500 and v>2200)])\n",
    "anterior_volumes = np.array([v for v in anterior_volumes if (v<4500 and v>2200)])\n",
    "posterior_volumes = np.array([v for v in posterior_volumes if (v<4500 and v>2200)])\n",
    "print(nonoutlier_volumes)\n",
    "print(anterior_volumes)\n",
    "print(posterior_volumes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Plot a histogram of all volumes that we have in our dataset and see how \n",
    "# our dataset measures against a slice of a normal population represented by the chart below.\n",
    "plt.title('Histogram of Non outlier volumes')\n",
    "plt.xlabel('Volume mm3')\n",
    "plt.hist(nonoutlier_volumes, bins=10)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Histogram of Anterior volumes')\n",
    "plt.xlabel('Volume mm3')\n",
    "plt.hist(nonoutlier_volumes, bins=10)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Histogram of Posterior volumes')\n",
    "plt.xlabel('Volume mm3')\n",
    "plt.hist(nonoutlier_volumes, bins=10)\n",
    "plt.show()\n",
    "\n",
    "plt.title('Histogram of all volumes')\n",
    "plt.xlabel('Volume mm3')\n",
    "plt.hist(all_volumes, bins=10)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/histogram1.png\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/histogram2.png\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/histogram3.png\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"img/nomogram_fem_right.svg\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any outliers? Why do you think it's so (might be not immediately obvious, but it's always a good idea to inspect) outliers closer. If you haven't found the images that do not belong, the histogram may help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world we would have precise information about the ages and conditions of our patients, and understanding how our dataset measures against population norm would be the integral part of clinical validation that we talked about in last lesson. Unfortunately, we do not have this information about this dataset, so we can only guess why it measures the way it is. If you would like to explore further, you can use the [calculator from HippoFit project](http://www.smanohar.com/biobank/calculator.html) to see how our dataset compares against different population slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything odd about the label files? We hope you did! The mask seems to have two classes, labeled with values `1` and `2` respectively. If you visualized sagittal or axial views, you might have gotten a good guess of what those are. Class 1 is the anterior segment of the hippocampus and class 2 is the posterior one. \n",
    "\n",
    "For the purpose of volume calculation we do not care about the distinction, however we will still train our network to differentiate between these two classes and the background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "Congratulations! You have finished Section 1. \n",
    "\n",
    "In this section you have inspected a dataset of MRI scans and related segmentations, represented as NIFTI files. We have visualized some slices, and understood the layout of the data. We have inspected file headers to understand what how the image dimensions relate to the physical world and we have understood how to measure our volume. We have then inspected dataset for outliers, and have created a clean set that is ready for consumption by our ML algorithm. \n",
    "\n",
    "In the next section you will create training and testing pipelines for a UNet-based machine learning model, run and monitor the execution, and will produce test metrics. This will arm you with all you need to use the model in the clinical context and reason about its performance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
